db.customers.createIndex({
  birthdate: 1
})

Creating a Single Field Index
Review the code below, which demonstrates how to create a single field index in a collection.


Create a Single Field Index
Use createIndex() to create a new index in a collection. Within the parentheses of createIndex(), include an object that contains the field and sort order.

db.customers.createIndex({
  birthdate: 1
})

Create a Unique Single Field Index
Add {unique:true} as a second, optional, parameter in createIndex() to force uniqueness in the index field values. Once the unique index is created, any inserts or updates including duplicated values in the collection for the index field/s will fail.

db.customers.createIndex({
  email: 1
},
{
  unique:true
})
MongoDB only creates the unique index if there is no duplication in the field values for the index field/s.


View the Indexes used in a Collection
Use getIndexes() to see all the indexes created in a collection.

db.customers.getIndexes()

Check if an index is being used on a query
Use explain() in a collection when running a query to see the Execution plan. This plan provides the details of the execution stages (IXSCAN , COLLSCAN, FETCH, SORT, etc.).

The IXSCAN stage indicates the query is using an index and what index is being selected.
The COLLSCAN stage indicates a collection scan is perform, not using any indexes.
The FETCH stage indicates documents are being read from the collection.
The SORT stage indicates documents are being sorted in memory.
db.customers.explain().find({
  birthdate: {
    $gt:ISODate("1995-08-01")
    }
  })
db.customers.explain().find({
  birthdate: {
    $gt:ISODate("1995-08-01")
    }
  }).sort({
    email:1
    })

View the Indexes used in a Collection
Use getIndexes() to see all the indexes created in a collection.

db.customers.getIndexes()

Check if an index is being used on a query
Use explain() in a collection when running a query to see the Execution plan. This plan provides the details of the execution stages (IXSCAN , COLLSCAN, FETCH, SORT, etc.).

The IXSCAN stage indicates the query is using an index and what index is being selected.
The COLLSCAN stage indicates a collection scan is perform, not using any indexes.
The FETCH stage indicates documents are being read from the collection.
The SORT stage indicates documents are being sorted in memory.
db.customers.explain().find({
  accounts: 627788
  })
  
  
  
  
  
  
  ********************************compoud
  
  
  Working with Compound Indexes
Review the code below, which demonstrates how to create a compound index in a collection.


Create a Compound Index
Use createIndex() to create a new index in a collection. Within the parentheses of createIndex(), include an object that contains two or more fields and their sort order.

db.customers.createIndex({
  active:1, 
  birthdate:-1,
  name:1
})

Order of Fields in a Compound Index
The order of the fields matters when creating the index and the sort order. It is recommended to list the fields in the following order: Equality, Sort, and Range.

Equality: field/s that matches on a single field value in a query
Sort: field/s that orders the results by in a query
Range: field/s that the query filter in a range of valid values
The following query includes an equality match on the active field, a sort on birthday (descending) and name (ascending), and a range query on birthday too.

db.customers.find({
  birthdate: {
    $gte:ISODate("1977-01-01")
    },
    active:true
    }).sort({
      birthdate:-1, 
      name:1
      })
Here's an example of an efficient index for this query:

db.customers.createIndex({
  active:1, 
  birthdate:-1,
  name:1
})

View the Indexes used in a Collection
Use getIndexes() to see all the indexes created in a collection.

db.customers.getIndexes()

Check if an index is being used on a query
Use explain() in a collection when running a query to see the Execution plan. This plan provides the details of the execution stages (IXSCAN , COLLSCAN, FETCH, SORT, etc.). Some of these are:

The IXSCAN stage indicates the query is using an index and what index is being selected.
The COLLSCAN stage indicates a collection scan is perform, not using any indexes.
The FETCH stage indicates documents are being read from the collection.
The SORT stage indicates documents are being sorted in memory.
db.customers.explain().find({
  birthdate: {
    $gte:ISODate("1977-01-01")
    },
  active:true
  }).sort({
    birthdate:-1,
    name:1
    })

Cover a query by the Index
An Index covers a query when MongoDB does not need to fetch the data from memory since all the required data is already returned by the index.

In most cases, we can use projections to return only the required fields and cover the query. Make sure those fields in the projection are in the index.

By adding the projection {name:1,birthdate:1,_id:0} in the previous query, we can limit the returned fields to only name and birthdate. These fields are part of the index and when we run the explain() command, the execution plan shows only two stages:

IXSCAN - Index scan using the compound index
PROJECTION_COVERED - All the information needed is returned by the index, no need to fetch from memory
db.customers.explain().find({
  birthdate: {
    $gte:ISODate("1977-01-01")
    },
  active:true
  },
  {name:1,
    birthdate:1, 
    _id:0
  }).sort({
    birthdate:-1,
    name:1
    })
	
	
******************** DROP Index

Deleting an Index
Review the code below, which demonstrates how to delete indexes in a collection.


View the Indexes used in a Collection
Use getIndexes() to see all the indexes created in a collection. There is always a default index in every collection on _id field. This index is used by MongoDB internally and cannot be deleted.

db.customers.getIndexes()

Delete an Index
Use dropIndex() to delete an existing index from a collection. Within the parentheses of dropIndex(), include an object representing the index key or provide the index name as a string.

Delete index by name:

db.customers.dropIndex(
  'active_1_birthdate_-1_name_1'
)
Delete index by key:

db.customers.dropIndex({
  active:1,
  birthdate:-1, 
  name:1
})

Delete Indexes
Use dropIndexes() to delete all the indexes from a collection, with the exception of the default index on _id.

db.customers.dropIndexes()
The dropIndexes() command also can accept an array of index names as a parameter to delete a specific list of indexes.

db.collection.dropIndexes([
  'index1name', 'index2name', 'index3name'
  ])
Previous


*********************INNER Working


Code Summary: How to Monitor Indexes
To use the $indexStats aggregation operator to return statistics regarding the use of each index for the collection, use the aggregate method on the collection. In this example, we are using a database called sample_analytics and a collection called customers:
RUN>>>>>
db.customers.aggregate([{ $indexStats: {} }])
The operator returns an array of objects, one for each index on the collection. In this case, based on the accesses.ops field values, you can determine which indexes are being used frequently and those that are not used at all.

[
  {
    name: '_id_',
    key: { _id: 1 },
    accesses: { ops: Long("0"), since: ISODate("2023-06-15T19:08:51.580Z") },
    host: '<cluster>.mongodb.net:27017'
  },
  ...
  {
    name: 'accounts_1',
    key: { accounts: 1 },
    accesses: { ops: Long("67"), since: ISODate("2023-06-21T20:20:25.955Z") },
    host: '<cluster>.mongodb.net:27017'
  },
  {
    name: 'email_1_username_1',
    key: { email: 1, username: 1 },
    accesses: { ops: Long("57"), since: ISODate("2023-06-21T20:20:25.997Z") },
    host: '<cluster>.mongodb.net:27017'
  },
  {
    name: 'username_1_email_1',
    key: { username: 1, email: 1 },
    accesses: { ops: Long("0"), since: ISODate("2023-06-21T20:20:26.040Z") },
    host: '<cluster>.mongodb.net:27017'
  }
]
To profile operations that happen on a MongoDB instance, you can enable the database profiler. In this example, the profiler is enabled by setting the first argument to 1 and setting a slowms threshold to 30, indicating that any operation that takes longer than 30 ms is considered slow. Slow operations are then recorded in a system.profile collection within the database. If we were to set the first argument to 0, the profiler would be disabled, and setting it to 2 would log all operations, regardless of how long they take.

db.setProfilingLevel(1, { slowms: 30 })
To test the profiler in action, run a query against the database that is rather taxing on resources. In this example, we are using the sample_airbnb database which is rather large. We are then sorting each document by host.

db.listingsAndReviews.find().sort({ host: 1 })
Run the following command to query the system.profile collection and return the most recently recorded query on the listingsAndReviews collection:

db.system.profile.find({ op: 'query', ns: 'sample_airbnb.listingsAndReviews'}).sort( {ts: -1}).limit(1)
After running the query, you should see the system.profile entry related to the query to sort all documents by host. The query exceeded the slowms threshold, required a collection scan (COLLSCAN), and an in memory sort (stage: 'SORT'). Also, take note of the ts field which gives a timestamp for the query.

{
  op: 'query',
  ns: 'sample_airbnb.listingsAndReviews',
  command: {
    find: 'listingsAndReviews',
    filter: {},
    sort: { host: 1 },
    ...
  },
  ...
  millis: 479,
  planSummary: 'COLLSCAN',
  execStats: {
    stage: 'SORT',
    ...
    }
  },
  ts: ISODate("2023-07-12T16:47:27.915Z"),
  ...
}
To speed up the query, create an index on the host field and run it again to see if it still shows up in the system.profile collection.

db.listingsAndReviews.createIndex({ host: 1 })

db.system.profile.find({ op: 'query', ns: 'sample_airbnb.listingsAndReviews'}).sort( {ts: -1}).limit(1)
After running ​​query, you should see that same entry for the query before we created an index as evidenced by the timestamp (ts). The index appears to have helped this query avoid going past the 30ms threshold.

{
  op: 'query',
  ns: 'sample_airbnb.listingsAndReviews',
  ...
  ts: ISODate("2023-07-12T16:47:27.915Z"),
  ...
}
*************************************INDEX USAGE*************************


Code Summary: Index Usage Details via Explain
To use the explain method in its default mode you can pass in the queryPlanner parameter, or, you can invoke the method with no parameter at all. When no parameter is provided, the default mode (queryPlanner) will be used.

db.collection.explain("queryPlanner").find({ timestamp: { $gt: 2 }, isActivated: true })

// or

db.collection.explain().find({ timestamp: { $gt: 2 }, isActivated: true })
To get specific information from the explain output, you can use vanilla JavaScript dot notation. For example, you can return only the value of queryPlanner.winningPlan with the following command:

db.collection.find({timestamp: {$gt: 2}, isActivated:              
true}).explain().queryPlanner.winningPlan
Similarly, to return only the rejectedPlans object from the explain output, you can also use dot notation like so:

db.collection.find({
  timestamp: { $gt: 2 }, isActivated: true
}).explain().queryPlanner.rejectedPlans
To use the explain method in executionStats mode to get detailed execution stats (including nReturned, totalKeysExamined, totalDocsExamined, and executionTimeMillis), you can pass the string executionStats to the explain method as a parameter, like so:

db.collection.explain("executionStats").find({
   timestamp: { $gt: 2 }, isActivated: true
}).sort({ rating: -1 })
The allPlansExecution verbosity mode will return output that contains scores that MongoDB’s query planner calculates for each index based on a number of factors. To use the explain method in allPlansExecution mode, you can pass the string allPlansExecution to the explain method as a parameter, like so:

db.collection.explain("allPlansExecution").find({
   timestamp: { $gt: 2 }, isActivated: true
});




*****************************************************Optimize

Code Summary: Optimized Compound Indexes
The code in this video uses some sample documents that you can insert into your MongoDB instance or Atlas Cluster with the following command in mongosh:

db.getSiblingDB("sample_game").users.insertMany([
  {
    _id: new ObjectId("6488bcfe84b99e26917f78b1"),
    dob: new Date("1987"),
    username: "testAccount",
    inactive: false,
    score: 800,
  },
  {
    _id: new ObjectId("6488bcfe84b99e26917f78b2"),
    dob: new Date("1988"),
    username: "exampleUser",
    inactive: false,
    score: 700,
  },
  {
    _id: new ObjectId("6488bcfe84b99e26917f78b3"),
    dob: new Date("1989"),
    username: "coolperson",
    inactive: true,
    score: 998,
  },
  {
    _id: new ObjectId("6488bcfe84b99e26917f78b4"),
    dob: new Date("1990"),
    username: "randomGuy",
    inactive: false,
    score: 500,
  },
])
To get a sorted list of current scores, for active users born between 1988 and 1990 sorted by current score in descending order, the following query was used:

db.users.find({
  dob: { $gte: new Date("1988"), $lte: new Date("1990") }, inactive: false 
}).sort({ current_score: -1 })
To arrive at the optimal index, break down the query into smaller parts, starting with the range fields. The resulting query will find users born between 1988 and 1990:

db.users.find({ dob: { $gte: new Date("1988"), $lte: new Date("1990") }
To see how the range query performs before any indexes are created, use the explain method in executionStats mode on the range query. To return only the executionStats object from the output, use the following command:

db.users.find({
  dob:{ $gte: new Date("1988"), $lte: new Date("1990")
}}).explain('executionStats').executionStats
To create an index to support the range query, use the following command to create an index on the dob field:

db.users.createIndex({ dob: 1 })
To test query performance after creating the index, run the following command to get only the executionStats object once again:

db.users.find({
  dob:{ $gte: new Date("1988"), $lte: new Date("1990")
}}).explain('executionStats').executionStats
To test out the next part of the query, add an equality check to filter out inactive users and return the executionStats from the explain output, like so:

db.users.find({
  dob: { $gte: new Date("1988"), $lte: new Date("1990") }, inactive: false
}).explain('executionStats').executionStats
To support the equality plus range query, create a compound index on the dob and inactive fields, like so:

db.users.createIndex({ dob: 1, inactive: 1})
To test the query after creating the compound index, run the following command once again. Notice that MongoDB doesn’t choose the dob-inactive index on its own.

db.users.find({
  dob: { $gte: new Date("1988"), $lte: new Date("1990") }, inactive: false
}).explain('executionStats').executionStats
To force MongoDB to use the compound index, use the hint method on the query itself, like so:

db.users.find({
  dob: { $gte: new Date("1988"), $lte: new Date("1990") },
  inactive: false,
}).hint({
  dob: 1, inactive: 1
}).explain("executionStats").executionStats
To try and improve the performance of the query, create a new compound index with the order of the fields reversed, such that the equality field (inactive) comes before the range field (dob):

db.users.createIndex({ inactive: 1, dob: 1})
To examine how the the inactive-dob index performs, get the executionStats from the explain output for the equality plus range query:

db.users.find({
  dob: { $gte: new Date("1988"), $lte: new Date("1990") },
  inactive: false,
}).explain("executionStats").executionStats
To examine how a query with all three fields (equality, sort, and range) performs with the current indexes, add the sort condition back to the query and return the executionStats from the explain output using the following command.

db.users.find({
  dob: { $gte: new Date("1988"), $lte: new Date("1990") },
  inactive: false,
}).sort({ current_score: -1 }).explain("executionStats").executionStats
To resolve the problem of the in-memory sort, create a compound index on the equality (inactive) and sort fields (current_score):

db.users.createIndex({ inactive: 1, current_score: 1 })
Test the inactive-current score index by getting the executionStats from the explain output, like so:

db.users.explain("executionStats").find({
  dob: { $gte: new Date("1988"), $lte: new Date("1990") },
  inactive: false,
}).sort({ current_score: -1 })
To further optimize the query, add the dob field to the index using the following command:

db.users.createIndex({ inactive: 1, current_score: 1, dob: 1 })
To ensure the new index is used, add the hint method to the query and return the executionStats from the explain output, like so:

db.users.explain("executionStats").find({
  dob: { $gte: new Date("1988"), $lte: new Date("1990") },
  inactive: false,
}).sort({ current_score: -1 }).hint({ inactive: 1, current_score: 1, dob: 1 })
The inactive, current_score, dob index has outperformed the others, leading us to the conclusion that the optimal order for indexes is to put equality fields first (in any order), followed by range fields, and sort fields behind both equality and range.

URL

https://learn.mongodb.com/learn/course/mongodb-indexes-ii/lesson-3-optimized-compound-indexes/learn?client=customer&page=2



*******************wildcard

Code Summary: Wildcard Indexes
The code in this video uses some sample documents that you can insert into your MongoDB instance or Atlas Cluster with the following command in mongosh:

db.getSiblingDB("sample_products").products.insertMany([
  {
    _id: new ObjectId("64a36318574fd20cd8fb9798"),
    sku: 111,
    product_name: "Stero Speakers",
    price: 100,
    stock: 5,
    product_attributes: { color: "black", size: "5x5x5", weight: "5lbs" },
  },
  {
    _id: new ObjectId("64a36318574fd20cd8fb9799"),
    sku: 121,
    product_name: "Bread",
    price: 2,
    stock: 50,
    product_attributes: {
      type: "white",
      calories: 100,
      weight: "24g",
      crust: "soft",
    },
  },
  {
    _id: new ObjectId("64a36318574fd20cd8fb979a"),
    sku: 131,
    product_name: "Milk",
    price: 3,
    stock: 20,
    product_attributes: {
      type: "2%",
      calories: 120,
      weight: "1L",
      brand: "Dairy Farmers",
    },
  },
]);
To create a wildcard index on the product attributes field, use the db.collection.createIndex() method, passing in the name of the field you want to index appended with a dot, dollar sign and two asterisks:

db.products.createIndex({ "product_attributes.$**" : 1 })
To test the query using the explain method, use dot notation to inspect the winning plan and confirm that the wildcard index is being used:

db.products.find({
  "product_attributes.crust": false,
}).explain().queryPlanner.winningPlan
To specify which fields to include or exclude in a wildcard index, set the value of a given field in a wildcard projection to 1 to include or 0 to exclude. To include the _id, while excluding the stock, and price fields, use the following command:

db.products.createIndex(
  { "$**": 1 },
  { wildcardProjection: { _id: 1, stock: 0, prices: 0 } }
)
To test the wildcard index with an query on the sku field, run the following query to return the winningPlan object from the explain output:

db.products.find({ sku: 111 }).explain().queryPlanner.winningPlan
To test the wildcard index even further, run another query on one of the product attribute fields, like so:

db.products.find({
  "product_attributes.crust": false
}).explain().queryPlanner.winningPlan
To create a compound wildcard index (starting in MongoDB 7.0) on the stock field and all of the product attributes fields, use the following command:

db.products.createIndex({
  stock: 1, "product_attributes.$**" : 1 
})

URL

https://learn.mongodb.com/learn/course/mongodb-indexes-ii/lesson-4-wildcard-indexes/learn?client=customer&page=2



URL

https://learn.mongodb.com/learn/course/mongodb-indexes-ii/lesson-5-partial-indexes/learn?client=customer&page=2

Code Summary: Partial Indexes
To create a partial index on the state field using a partialFilterExpression that only indexes documents with a population greater than or equal to 10,000, use the following command:

db.zips.createIndex(
  { state: 1 },
  { partialFilterExpression: { pop: { $gte: 10000 } } }
)
To test if the partial index is being used, run a query for documents with a state of California using the explain method. To return the most relevant results, use dot notation to return only the queryPlanner.winningPlan object, as shown in the following command:

db.zips.find({ state: "CA" }).explain().queryPlanner.winningPlan
Note that the partial index wasn’t used since there are documents in the collection with a state of California, that also have a population less than 10,000. As a result, the index was ineligible.

To test if the partial index is used on a different query, one that finds documents that have a population of less than or equal to 10,000, use the following command:

db.zips.find({ state: "CA", pop: { $gte: 10000 } }).explain().queryPlanner.winningPlan
Note that the partial index was used, since the requested documents match the partial filter expression.

To test the partial index one more time, run the following command to get the explain output and return just the queryPlanner.winningPlan object for a query that finds documents with a population of 12,000 or fewer:

db.zips.find({ state: "CA", pop: { $lte: 12000 } }).explain().queryPlanner.winningPlan
Note that the partial index wasn’t used since there are documents in the result set that have a population of less than 10,000.




**************
URL
https://learn.mongodb.com/learn/course/mongodb-indexes-ii/lesson-6-sparse-indexes/learn?client=customer&page=2

Code Summary: Sparse Indexes
The code in this video uses some sample documents that you can insert into your MongoDB instance or Atlas Cluster with the following command in mongosh:

db.getSiblingDB("sample_db").sparseExample.insertMany([
  {
    _id: new ObjectId("64920144bf3922c17f7181ca"),
    username: "coolUser",
    avatar_url: "https://api.multiavatar.com/coolUser.svg",
  },
  {
    _id: new ObjectId("64920144bf3922c17f7181cb"),
    username: "testUser",
    avatar_url: "https://api.multiavatar.com/testUser.svg",
  },
  {
    _id: new ObjectId("64920144bf3922c17f7181cc"),
    username: "anotherUser",
    avatar_url: "https://api.multiavatar.com/anotherUser.svg",
  },
  { _id: new ObjectId("64920173bf3922c17f7181cd"), username: "test" },
]);
To create a sparse index on the avatar_url field use the createIndex method and provide an index specification document containing the field we want to index. For the options object, add an object with a field sparse and a value of true, as shown in the following command:

db.sparseExample.createIndex({ avatar_url: 1 }, { sparse: true })
To test the index, run a query that looks for all documents in the sparseExample collection that contain an avatar image. A total of three documents should be returned:

db.sparseExample.find({ avatar_url: { $exists: true } })
To see if the query is using the sparse index, use explain with the executionStats verbosity level. This command uses dot notation to return just the executionStats object from the explain output:

db.sparseExample.find({ avatar_url: { $exists: true } }).explain("executionStats").executionStats
Note In addition to the index being listed in executionStages, the isSparse field in the execution stats output should also have a value of true indicating that the index was used.

To test the sparse index one more time, run the following command to get the explain output and return just the executionStats object for a query that finds all documents sorted by avatar_url:

db.sparseExample.find().sort({ avatar_url: 1 }).explain("executionStats").executionStats
Note that the sparse index wasn’t used since using it would lead to incomplete results



*******************time series

Code Summary: Time Series Collections
To create a time series collection, called weather, use the db.createCollection method. The first argument should be the name of the collection, and the second argument should be an options object. The options object should contain the following fields, which align with the three components in a time series collection — time, metadata, and measurements.

timeField - corresponds to the name of the field in the document that contains a valid BSON date type.
metaField - optional but highly recommended field that is a label or tag associated with the time series. Typically this would be something like a device id or the name of the sensor that produces the measurements
granularity - another optional field that indicates the frequency at which we want to collect data (seconds, minutes, hours).
db.createCollection("weather", {
  timeseries: {
    timeField: "timestamp",
    metaField: "metadata",
    granularity: "hours",
  },
})
After running the command you will see an output that looks like this:

{ ok: 1 }
To test that the internal clustered index is being used, run the following command. This command uses JavaScript dot notation to access fields relevant to index usage. It accesses the stages object, and the first array element within it – the $cursor object. This stage contains the queryPlanner.winningPlan object.

Note: explain output for queries on time-series collections will look different than your typical explain output. It should be read as an aggregation output.

db.weather.find({
  timestamp: ISODate("2021-05-18T00:00:00.000Z")
}).explain().stages[0].$cursor.queryPlanner.winningPlan
After running the query, you should see a stage property with a value of CLUSTERED_IXSCAN, indicating that the internal clustered index was used for the query:

{
  stage: 'CLUSTERED_IXSCAN',
  filter: {  },
  direction: 'forward',
  minRecord: ObjectId("607b76800000000000000000"),
  maxRecord: ObjectId("60a30380ffffffffffffffff")
}
MongoDB recommends adding one or more secondary compound indexes on the fields designated as the timeField and metaField. To create a secondary index on the metadata.sensorid and timestamp fields, use the following command:

db.weather.createIndex( { "metadata.sensorId": 1, "timestamp": 1 } )
After creating the secondary compound index, test it with the following command. This is a query (with explain) to find all documents with a specific sensorid sorted by timestamp:

db.weather.explain().find({ "metadata.sensorId": 5578 }).sort({ "timestamp": 1 })
In the explain output, check to see if the queryPlanner.winningPlan within the $cursor object/stage has an inputStage of IXSCAN and an indexName of metadata.sensorId_1_timestamp_1. If so, this indicates that the secondary index was used.

// truncated for space
stages: [
  {
    $cursor: {
      queryPlanner: {
...        
        winningPlan: {
          stage: "FETCH",
          inputStage: {
            stage: "IXSCAN",
            keyPattern: {
              "meta.sensorId": 1,
              "control.min.timestamp": 1,
              "control.max.timestamp": 1,
            },
            indexName: "metadata.sensorId_1_timestamp_1"
         ...
            },
          },
        },
      },
    },
  },
  
  
  
  URL
  https://learn.mongodb.com/learn/course/mongodb-indexes-ii/lesson-8-time-series-collections/learn?client=customer&page=2
  
  
  
  
  Code Summary: How to Monitor Indexes
To use the $indexStats aggregation operator to return statistics regarding the use of each index for the collection, use the aggregate method on the collection. In this example, we are using a database called sample_analytics and a collection called customers:

db.customers.aggregate([{ $indexStats: {} }])
The operator returns an array of objects, one for each index on the collection. In this case, based on the accesses.ops field values, you can determine which indexes are being used frequently and those that are not used at all.

[
  {
    name: '_id_',
    key: { _id: 1 },
    accesses: { ops: Long("0"), since: ISODate("2023-06-15T19:08:51.580Z") },
    host: '<cluster>.mongodb.net:27017'
  },
  ...
  {
    name: 'accounts_1',
    key: { accounts: 1 },
    accesses: { ops: Long("67"), since: ISODate("2023-06-21T20:20:25.955Z") },
    host: '<cluster>.mongodb.net:27017'
  },
  {
    name: 'email_1_username_1',
    key: { email: 1, username: 1 },
    accesses: { ops: Long("57"), since: ISODate("2023-06-21T20:20:25.997Z") },
    host: '<cluster>.mongodb.net:27017'
  },
  {
    name: 'username_1_email_1',
    key: { username: 1, email: 1 },
    accesses: { ops: Long("0"), since: ISODate("2023-06-21T20:20:26.040Z") },
    host: '<cluster>.mongodb.net:27017'
  }
]
To profile operations that happen on a MongoDB instance, you can enable the database profiler. In this example, the profiler is enabled by setting the first argument to 1 and setting a slowms threshold to 30, indicating that any operation that takes longer than 30 ms is considered slow. Slow operations are then recorded in a system.profile collection within the database. If we were to set the first argument to 0, the profiler would be disabled, and setting it to 2 would log all operations, regardless of how long they take.

db.setProfilingLevel(1, { slowms: 30 })
To test the profiler in action, run a query against the database that is rather taxing on resources. In this example, we are using the sample_airbnb database which is rather large. We are then sorting each document by host.

db.listingsAndReviews.find().sort({ host: 1 })
Run the following command to query the system.profile collection and return the most recently recorded query on the listingsAndReviews collection:

db.system.profile.find({ op: 'query', ns: 'sample_airbnb.listingsAndReviews'}).sort( {ts: -1}).limit(1)
After running the query, you should see the system.profile entry related to the query to sort all documents by host. The query exceeded the slowms threshold, required a collection scan (COLLSCAN), and an in memory sort (stage: 'SORT'). Also, take note of the ts field which gives a timestamp for the query.

{
  op: 'query',
  ns: 'sample_airbnb.listingsAndReviews',
  command: {
    find: 'listingsAndReviews',
    filter: {},
    sort: { host: 1 },
    ...
  },
  ...
  millis: 479,
  planSummary: 'COLLSCAN',
  execStats: {
    stage: 'SORT',
    ...
    }
  },
  ts: ISODate("2023-07-12T16:47:27.915Z"),
  ...
}
To speed up the query, create an index on the host field and run it again to see if it still shows up in the system.profile collection.

db.listingsAndReviews.createIndex({ host: 1 })

db.system.profile.find({ op: 'query', ns: 'sample_airbnb.listingsAndReviews'}).sort( {ts: -1}).limit(1)
After running ​​query, you should see that same entry for the query before we created an index as evidenced by the timestamp (ts). The index appears to have helped this query avoid going past the 30ms threshold.

{
  op: 'query',
  ns: 'sample_airbnb.listingsAndReviews',
  ...
  ts: ISODate("2023-07-12T16:47:27.915Z"),
  ...
}


***********************************************************

https://learn.mongodb.com/learn/course/mongodb-indexes-ii/lesson-9-how-to-monitor-indexes/practice?client=customer&page=2


URL   What is explain
https://learn.mongodb.com/learn/course/mongodb-indexes-ii/lesson-2-index-usage-details-via-explain/learn?client=customer&page=2